{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aba3cf9-a0f0-41b0-9fb7-758b78f454cf",
   "metadata": {},
   "source": [
    "# 1. Define imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5d64cdbe-9bdd-4421-8140-9af88f9b0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46792fc-7670-4026-b84e-2f17bbb47f77",
   "metadata": {},
   "source": [
    "# 2. Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "459a5706-9566-45ea-b11e-5c12dcd9e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepfake Detection\n",
    "df_model = load_model('models/DeepFake_model_ver4_full.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ffc3ac5e-be88-41d6-9359-e7054cde56db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequential name=sequential_1, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c80c8da5-c98a-4ced-9178-2350fbd5f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaker Identification\n",
    "si_model = load_model('models/speaker_identification_model_ver4_segment.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d4425621-af05-4e35-b4c2-0b88dc3632f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequential name=sequential_2, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(si_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaf6f43-b3f0-4be0-a428-59c9a230c07a",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cb3620a9-a422-4987-a47f-1c20a82c626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_segment(segment_features):\n",
    "    # Load the scaler\n",
    "    df_scaler = joblib.load('scalers/df_scaler.pkl') # Deepfake Detection\n",
    "    si_scaler = joblib.load('scalers/vr_scaler.pkl') # Speaker Identification\n",
    "    \n",
    "    # Scale the features using the pre-fitted scaler\n",
    "    # reshaped = df_scaler.transform([segment_features])  # Deepfake Detection\n",
    "    reshaped = si_scaler.transform([segment_features])  # Speaker Identification\n",
    "    \n",
    "    # Reshape to match the model's input shape (num_features, 1, 1)\n",
    "    reshaped = reshaped.reshape(1, reshaped.shape[1], 1, 1)  # Shape: (1, num_features, 1, 1)\n",
    "    print(reshaped.shape)\n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c35795a9-12a1-47ad-9578-8133112654cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_segments(segment_data):\n",
    "    confidence_scores = []  # Store the scores for each segment\n",
    "    # iterate each row\n",
    "    for i in range(0, segment_data.shape[0]):\n",
    "        # Reshape the segment features to match the model's input\n",
    "        segment_row = segment_data[i]\n",
    "        \n",
    "        reshaped_segment = reshape_segment(segment_row)\n",
    "        \n",
    "        # Predict the confidence score using the model\n",
    "        # predictions = df_model.predict(reshaped_segment) # Deepfake Detection\n",
    "        predictions = si_model.predict(reshaped_segment) # Speaker Identification\n",
    "    \n",
    "        confidence = predictions[0][0]\n",
    "        \n",
    "        # Store the confidence score\n",
    "        confidence_scores.append(confidence)\n",
    "\n",
    "    return confidence_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c4620-eb42-4ead-b7cd-578a023c2690",
   "metadata": {},
   "source": [
    "# 4. Load single data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2d165f33-c399-4a12-907f-448d3699a00f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  file_name  mfcc_feature1  mfcc_feature2  mfcc_feature3  \\\n",
      "0  Testspeaker_notonDS3.mp3      -466.5779       97.13960     -26.258076   \n",
      "1  Testspeaker_notonDS3.mp3      -417.8303      132.05717     -34.885048   \n",
      "2  Testspeaker_notonDS3.mp3      -367.9756      157.65352     -55.006313   \n",
      "\n",
      "   mfcc_feature4  mfcc_feature5  mfcc_feature6  mfcc_feature7  mfcc_feature8  \\\n",
      "0      27.655281       6.587523       3.792437      -4.188441      -5.875909   \n",
      "1      61.646320       1.144908      13.338906      -0.824676      -3.358345   \n",
      "2      59.517086      -2.079819       5.414917      -7.052460       9.160208   \n",
      "\n",
      "   mfcc_feature9  ...  SpectralBandwidth78  SpectralBandwidth79  \\\n",
      "0      -2.479454  ...          1167.923996          1100.285335   \n",
      "1      -9.944326  ...          2281.718069          2043.592242   \n",
      "2      -8.061013  ...          1377.506934          1340.238107   \n",
      "\n",
      "   SpectralBandwidth80  SpectralBandwidth81  SpectralBandwidth82  \\\n",
      "0           873.838629           975.967077          1315.021547   \n",
      "1          1644.462518          1216.687526          1230.475282   \n",
      "2          1497.723533          2376.451402          1800.868859   \n",
      "\n",
      "   SpectralBandwidth83  SpectralBandwidth84  SpectralBandwidth85  \\\n",
      "0          1117.628494          1102.258886           983.432821   \n",
      "1          1261.804122          1247.401012           837.542714   \n",
      "2          1623.295591          1605.047158          1624.717524   \n",
      "\n",
      "   SpectralBandwidth86  SpectralBandwidth87  \n",
      "0           998.836714          2589.473598  \n",
      "1          1223.532878          2128.174018  \n",
      "2          1695.281326          1813.043184  \n",
      "\n",
      "[3 rows x 388 columns]\n",
      "(1, 387, 1, 1)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "(1, 387, 1, 1)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "(1, 387, 1, 1)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# Deepfake Detection test\n",
    "# segment_data = pd.read_csv('result\\deepfake_detection\\\\tests\\human_t1.csv') # human\n",
    "# segment_data = pd.read_csv('result\\deepfake_detection\\\\tests\\human_t2.csv') # human\n",
    "# segment_data = pd.read_csv('result\\deepfake_detection\\\\tests\\synthetic_t1.csv') # synthetic\n",
    "# segment_data = pd.read_csv('result\\deepfake_detection\\\\tests\\synthetic_t2.csv') # synthetic\n",
    "\n",
    "# Speaker Identification test\n",
    "# segment_data = pd.read_csv('result\\deepfake_detection\\\\tests\\human_t2.csv') # same\n",
    "segment_data = pd.read_csv('result\\\\voice_recognition\\\\test_full\\\\vr_full_segment_same.csv') # same\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Output: \n",
    "Deepfake Detection = 1 Human : 0 AI\n",
    "Speaker Identification = 1 Speaker : 0 Not Speaker\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(segment_data)\n",
    "segment_data = segment_data.drop(columns=['file_name']).values\n",
    "confidence_scores = evaluate_segments(segment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "90dde2d6-0b51-45ac-a5b5-a3af29829fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.999353, 0.92696726, 0.9998171]\n",
      "0.9753791093826294\n"
     ]
    }
   ],
   "source": [
    "print(confidence_scores)\n",
    "\n",
    "def Average(confidence_scores): \n",
    "    return sum(confidence_scores) / len(confidence_scores) \n",
    "\n",
    "overall = Average(confidence_scores)\n",
    "print(overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05cff87-d423-404a-899c-0dab0cd2aaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546342f1-5e84-4d45-a92d-019a24e9049b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venvAudio)",
   "language": "python",
   "name": "pythonaudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
