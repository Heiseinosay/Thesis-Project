{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602e51ee-a18d-4b81-8cc0-acc3ef6e9714",
   "metadata": {},
   "source": [
    "# 1. Define Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee2becd-d083-4b8b-8a5a-65ce8b217b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0721a-c959-4cbd-99f7-45e0a0ec683b",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759e6aa7-8c9f-4e46-91a5-2693319950f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stereo to mono (two or more channels to sigle channel)\n",
    "def pre_process(audio_file):\n",
    "    # conert to single hz\n",
    "    target_sr = 22050 \n",
    "    # Load the data with resampling\n",
    "    signal, sr = librosa.load(audio_file, sr=target_sr, mono=False, res_type='kaiser_best')\n",
    "    if signal.ndim > 1:  # Check if the signal is stereo\n",
    "        print(True)\n",
    "        # Convert stereo to mono by averaging the channels\n",
    "        signal = np.mean(signal, axis=0)\n",
    "    return signal, target_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c67ed11-25b9-4845-ae96-e76c4f2f53ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For training. No need to copy\n",
    "def pre_process_hugging_face(audio_array, original_sr):\n",
    "    # Target sampling rate for resampling\n",
    "    target_sr = 22050 \n",
    "    \n",
    "    # Resample the audio array to target sampling rate\n",
    "    signal = librosa.resample(audio_array.astype(np.float32), orig_sr=original_sr, target_sr=target_sr)\n",
    "    \n",
    "    # Check if it's stereo (more than 1 channel)\n",
    "    if signal.ndim > 1:\n",
    "        # Convert stereo to mono by averaging the channels\n",
    "        signal = np.mean(signal, axis=0)\n",
    "    \n",
    "    return signal, target_sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d86c8-66b1-498b-a27f-3dc67d67c116",
   "metadata": {},
   "source": [
    "# 3. Extract MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6896a12d-52a5-4ea4-80c5-83a1efdcf6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MFCC(signal, sr):\n",
    "    signal.shape # The output is 1 dimensional array with the following value\n",
    "    # Sample rate\n",
    "    # print(\"Signal: \", signal)\n",
    "    # print(\"Sample Rate: \", sr)\n",
    "\n",
    "    # Extract MFCC\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13)\n",
    "    # print(mfccs.shape) # First value is the number of rows, second value is the number of columns or frames\n",
    "    # print(mfccs)\n",
    "\n",
    "    # First Derivative -  Capture the temporal dynamics of the speech signal, providing information about how the MFCCs are changing.\n",
    "    delta_mfccs = librosa.feature.delta(mfccs)\n",
    "    # Second Derivative - Capture the dynamics of the delta features, providing additional information about the speech signalâ€™s temporal characteristics.\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "\n",
    "    comprehensive_mfcc = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
    "    # print(comprehensive_mfcc)\n",
    "    return comprehensive_mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc0d211-cebb-4faf-b0a9-be00ed9a367d",
   "metadata": {},
   "source": [
    "# 4. Extract RMS, ZCR, SC, SB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c9843-88ac-4e68-95fd-432bada0bd70",
   "metadata": {},
   "source": [
    "### Note: \n",
    "#### If you want the mean switch the return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caebdff6-9be0-4831-bd4a-370462287e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio, sr, target_duration = 2, target_sr = 22050):\n",
    "    # exctract RMS, ZCR, SC, SB\n",
    "    # audio, sr = librosa.load(file_path, sr=target_sr)  # Load audio file\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)  # Get duration in seconds\n",
    "    \n",
    "    # print(duration)\n",
    "\n",
    "    FRAME_LENGTH = 1024\n",
    "    HOP_LENGTH = 512\n",
    "    \n",
    "    if duration >= target_duration:\n",
    "        # print(True)\n",
    "        # Convert target duration to samples\n",
    "        target_samples = int(target_duration * sr)\n",
    "        \n",
    "        # Get the center point of the audio\n",
    "        center = len(audio) // 2\n",
    "        # print(\"Center: \" , center)\n",
    "        # Calculate the start and end points for cropping\n",
    "        start_sample = max(0, center - target_samples // 2)\n",
    "        end_sample = min(len(audio), center + target_samples // 2)\n",
    "        \n",
    "        # Crop the audio around the center\n",
    "        cropped_audio = audio[start_sample:end_sample]\n",
    "        # print(cropped_audio.shape)\n",
    "\n",
    "        # Check if the audio was cropped\n",
    "        # ipd.display(ipd.Audio(cropped_audio, rate=sr))\n",
    "\n",
    "        # Extract RMS from the cropped audio\n",
    "        rms_cropped = librosa.feature.rms(y=cropped_audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)[0]\n",
    "        # Extract ZCR from the cropped audio\n",
    "        zcr_cropped = librosa.feature.zero_crossing_rate(y=cropped_audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)[0]\n",
    "        # Extract spectral centroid from the cropped audio\n",
    "        sc_cropped = librosa.feature.spectral_centroid(y=cropped_audio, sr=sr, n_fft=FRAME_LENGTH, hop_length=HOP_LENGTH)[0]\n",
    "        # Extract spectral bandwidth from the cropped audio\n",
    "        sb_cropped = librosa.feature.spectral_bandwidth(y=cropped_audio, sr=sr, n_fft=FRAME_LENGTH, hop_length=HOP_LENGTH)[0]\n",
    "        \n",
    "        # return rms_cropped, zcr_cropped, sc_cropped, sb_cropped\n",
    "        return np.mean(rms_cropped), np.mean(zcr_cropped), np.mean(sc_cropped), np.mean(sb_cropped) # for mean\n",
    "    else:\n",
    "        # If duration is less than target, process the entire audio\n",
    "        # print(False)\n",
    "        rms_full = librosa.feature.rms(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)[0]\n",
    "        zcr_full = librosa.feature.zero_crossing_rate(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)[0]\n",
    "        sc_full = librosa.feature.spectral_centroid(y=audio, sr=sr, n_fft=FRAME_LENGTH, hop_length=HOP_LENGTH)[0]\n",
    "        sb_full = librosa.feature.spectral_bandwidth(y=audio, sr=sr, n_fft=FRAME_LENGTH, hop_length=HOP_LENGTH)[0]\n",
    "        # return rms_full, zcr_full, sc_full, sb_full\n",
    "        return np.mean(rms_full), np.mean(zcr_full), np.mean(sc_full), np.mean(sb_full) # for mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab0d9a7-cb9d-4308-9022-24c2e979e827",
   "metadata": {},
   "source": [
    "# 5. Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fbd491b-83ac-4058-8e15-8f33befe1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process all files in a given folder and accumulate features\n",
    "# README: For complete values\n",
    "def process_audio_files(folder_path, output_file_name):\n",
    "    mfcc_features = []\n",
    "    rms_values = []\n",
    "    zcr_values = []\n",
    "    sc_values = []\n",
    "    sb_values = []\n",
    "    file_names = []  # List to store file names\n",
    "    for root, dirs, files in tqdm(os.walk(folder_path)):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp3') or file.endswith('.wav'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Processing {file}\")\n",
    "                \n",
    "                # Load the audio signal\n",
    "                # signal, sr = librosa.load(file_path, sr=22050)\n",
    "                signal, sr = pre_process(file_path)\n",
    "                \n",
    "                # Extract MFCC features\n",
    "                mfcc = extract_MFCC(signal, sr)\n",
    "                mfcc_mean = np.mean(mfcc.T, axis=0)\n",
    "                mfcc_features.append(mfcc_mean)\n",
    "                \n",
    "                # Extract RMS, ZCR, SC, SB features\n",
    "                rms, zcr, sc, sb = extract_features(signal, sr)\n",
    "                rms_values.append(rms)\n",
    "                zcr_values.append(zcr)\n",
    "                sc_values.append(sc)\n",
    "                sb_values.append(sb)\n",
    "\n",
    "                file_names.append(file)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    print(\"Number of processed files: \", len(rms_values))\n",
    "    # Create dataframes for MFCC and other features\n",
    "    mfcc_df = pd.DataFrame(mfcc_features, columns=[f'mfcc_feature{i+1}' for i in range(mfcc_features[0].shape[0])])\n",
    "    rms_df = pd.DataFrame(rms_values, columns=[f'RMS{i+1}' for i in range(len(rms_values[0]))])\n",
    "    zcr_df = pd.DataFrame(zcr_values, columns=[f'ZCR{i+1}' for i in range(len(zcr_values[0]))])\n",
    "    sc_df = pd.DataFrame(sc_values, columns=[f'SpectralCentroid{i+1}' for i in range(len(sc_values[0]))])\n",
    "    sb_df = pd.DataFrame(sb_values, columns=[f'SpectralBandwidth{i+1}' for i in range(len(sb_values[0]))])\n",
    "\n",
    "    # Combine all features into a single DataFrame\n",
    "    combined_df = pd.concat([pd.DataFrame(file_names, columns=['file_name']), mfcc_df, rms_df, zcr_df, sc_df, sb_df], axis=1)\n",
    "\n",
    "    create_csv(combined_df, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d560525a-84eb-40c1-a664-4e072121e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# README: for mean values\n",
    "def process_audio_files_mean(folder_path, output_file_name):\n",
    "    mfcc_features = []\n",
    "    rms_values = []\n",
    "    zcr_values = []\n",
    "    sc_values = []\n",
    "    sb_values = []\n",
    "    file_names = []  # To keep track of file names\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp3') or file.endswith('.wav') or file.endswith('.flac'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Processing {file}\")\n",
    "                # Load the audio signal\n",
    "                signal, sr = pre_process(file_path)\n",
    "\n",
    "                # Extract MFCC features and calculate the mean over time\n",
    "                mfcc = extract_MFCC(signal, sr)\n",
    "                mfcc_mean = np.mean(mfcc.T, axis=0)\n",
    "                mfcc_features.append(mfcc_mean)\n",
    "\n",
    "                # Extract mean values of RMS, ZCR, SC, SB for the audio file\n",
    "                rms, zcr, sc, sb = extract_features(signal, sr)\n",
    "                rms_values.append(rms)\n",
    "                zcr_values.append(zcr)\n",
    "                sc_values.append(sc)\n",
    "                sb_values.append(sb)\n",
    "\n",
    "                # Append file name for reference\n",
    "                file_names.append(file)\n",
    "\n",
    "    print(\"Number of processed files: \", len(rms_values))\n",
    "\n",
    "    # Create DataFrame for MFCC features\n",
    "    mfcc_df = pd.DataFrame(mfcc_features, columns=[f'mfcc_feature{i+1}' for i in range(mfcc_features[0].shape[0])])\n",
    "\n",
    "    # Create a DataFrame for the mean values of additional features\n",
    "    df = pd.DataFrame({\n",
    "        'MeanRMS': rms_values,\n",
    "        'MeanZCR': zcr_values,\n",
    "        'MeanSpectralCentroid': sc_values,\n",
    "        'MeanSpectralBandwidth': sb_values\n",
    "    })\n",
    "\n",
    "    # Combine MFCC features, additional mean features, and file names\n",
    "    combined_df = pd.concat([pd.DataFrame(file_names, columns=['file_name']), mfcc_df, df], axis=1)\n",
    "\n",
    "    create_csv(combined_df, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a853b1e7-d4f7-4976-91be-a72f89fb4c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For hugging face dataset only\n",
    "# Full values\n",
    "def process_audio_files_hugging_face(dataset, output_file_name):\n",
    "    mfcc_features = []\n",
    "    rms_values = []\n",
    "    zcr_values = []\n",
    "    sc_values = []\n",
    "    sb_values = []\n",
    "    file_names = []  # List to store file names\n",
    "\n",
    "    # Loop through the dataset\n",
    "    for i, item in tqdm(enumerate(dataset['train'])):\n",
    "        # Access the audio path and file name\n",
    "        file_name = item['audio']['path']\n",
    "        arr_audio = item['audio']['array']\n",
    "        sampling_rate = item['audio']['sampling_rate']\n",
    "        print(f\"Processing {file_name}\")\n",
    "        \n",
    "        # Load the audio signal\n",
    "        signal, sr = pre_process_hugging_face(arr_audio, sampling_rate)\n",
    "\n",
    "        # Extract MFCC features\n",
    "        mfcc = extract_MFCC(signal, sr)\n",
    "        mfcc_mean = np.mean(mfcc.T, axis=0)\n",
    "        mfcc_features.append(mfcc_mean)\n",
    "\n",
    "        # Extract RMS, ZCR, SC, SB features\n",
    "        rms, zcr, sc, sb = extract_features(signal, sr)\n",
    "        rms_values.append(rms)\n",
    "        zcr_values.append(zcr)\n",
    "        sc_values.append(sc)\n",
    "        sb_values.append(sb)\n",
    "\n",
    "        file_names.append(file_name)\n",
    "\n",
    "    # Create dataframes for MFCC and other features\n",
    "    mfcc_df = pd.DataFrame(mfcc_features, columns=[f'mfcc_feature{i+1}' for i in range(mfcc_features[0].shape[0])])\n",
    "    rms_df = pd.DataFrame(rms_values, columns=[f'RMS{i+1}' for i in range(len(rms_values[0]))])\n",
    "    zcr_df = pd.DataFrame(zcr_values, columns=[f'ZCR{i+1}' for i in range(len(zcr_values[0]))])\n",
    "    sc_df = pd.DataFrame(sc_values, columns=[f'SpectralCentroid{i+1}' for i in range(len(sc_values[0]))])\n",
    "    sb_df = pd.DataFrame(sb_values, columns=[f'SpectralBandwidth{i+1}' for i in range(len(sb_values[0]))])\n",
    "    \n",
    "\n",
    "    # Combine all features into a single DataFrame\n",
    "    combined_df = pd.concat([pd.DataFrame(file_names, columns=['file_name']), mfcc_df, rms_df, zcr_df, sc_df, sb_df], axis=1)\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    create_csv(combined_df, output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77979976-03b6-464b-b409-99b0e0a25f26",
   "metadata": {},
   "source": [
    "# 6. Save to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e30f296-8cbf-4549-9d60-251c4bd875d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a annotated dataset\n",
    "def create_csv(combined_df, output_file_name):\n",
    "    # Save to CSV\n",
    "    combined_df.to_csv(f\"result/{output_file_name}\", index=False)\n",
    "    print(f\"Successfully saved combined features to {output_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1eb2a-93e6-47e0-b6fd-c0938eb301f3",
   "metadata": {},
   "source": [
    "# 7. Extract Training Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d13f45ed-225c-4ba6-9de8-42ed397d45ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing spanish86_cloned.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file107_2024-10-08_11-56-11.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file108_2024-10-08_12-11-52.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file110_2024-10-08_12-12-18.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file112_2024-10-08_12-13-16.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file115_2024-10-08_12-13-48.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file116_2024-10-08_12-16-58.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file119_2024-10-08_12-18-59.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file122_2024-10-08_12-19-22.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file125_2024-10-08_12-20-51.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file127_2024-10-08_12-21-13.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file12_2024-10-06_18-55-26.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file130_2024-10-08_12-22-14.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file134_2024-10-08_12-24-46.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file137_2024-10-08_12-59-54.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file138_2024-10-08_13-01-01.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file13_2024-10-06_18-56-07.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file140_2024-10-08_13-12-58.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file143_2024-10-08_16-21-52.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file145_2024-10-08_16-22-24.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file146_2024-10-08_16-31-50.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file147_2024-10-08_16-32-15.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file149_2024-10-08_16-55-53.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file14_2024-10-06_18-56-33.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file150_2024-10-08_16-56-20.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file152_2024-10-08_16-56-55.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file153_2024-10-08_16-57-12.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file156_2024-10-08_17-01-36.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file160_2024-10-08_17-05-18.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file16_2024-10-06_18-56-58.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file171_2024-10-08_17-05-41.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file172_2024-10-08_17-06-19.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file173_2024-10-08_17-06-41.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file174_2024-10-08_17-07-03.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file175_2024-10-08_17-07-31.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file179_2024-10-08_17-07-58.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file23_2024-10-06_18-57-33.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file31_2024-10-06_18-59-50.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file33_2024-10-06_19-00-37.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file34_2024-10-06_19-01-02.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file39_2024-10-06_19-01-38.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file3_2024-10-06_18-51-33.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file41_2024-10-06_19-02-25.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file48_2024-10-06_19-03-07.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file50_2024-10-06_19-03-37.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file55_2024-10-06_19-04-11.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file66_2024-10-06_19-06-03.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file67_2024-10-06_19-06-33.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file68_2024-10-06_19-07-13.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file73_2024-10-06_19-07-48.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file78_2024-10-06_19-08-18.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file81_2024-10-06_19-08-51.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file82_2024-10-06_22-13-10.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file83_2024-10-06_22-43-20.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file86_2024-10-06_22-47-35.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file89_2024-10-06_22-49-23.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file97_2024-10-07_00-23-06.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file99_2024-10-08_11-55-42.mp3\n",
      "True\n",
      "Processing speechify_cloned_voice_file9_2024-10-06_18-54-55.mp3\n",
      "True\n",
      "Processing swedish4_cloned.mp3\n",
      "True\n",
      "Processing tagalog12_cloned.mp3\n",
      "True\n",
      "Processing taiwanese6_cloned.mp3\n",
      "True\n",
      "Processing tajiki1_cloned.mp3\n",
      "True\n",
      "Processing thai10_cloned.mp3\n",
      "True\n",
      "Processing tigrigna5_cloned.mp3\n",
      "True\n",
      "Processing turkish6_cloned.mp3\n",
      "True\n",
      "Processing urdo10_cloned.mp3\n",
      "True\n",
      "Processing yidish3_cloned.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:20, 20.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Number of processed files:  68\n",
      "Successfully saved combined features to deepfake_detection/Synthetic_full_speechify.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------Deep fake detection------------------------------------------------------\n",
    "human_audio_folder = \"AudioData/human\"\n",
    "synthetic_audio_folder = \"AudioData/synthetic/Speechify\"\n",
    "\n",
    "# Human\n",
    "# process_audio_files(human_audio_folder, \"deepfake_detection/Human_full_official.csv\")\n",
    "\n",
    "# AI \n",
    "# process_audio_files(synthetic_audio_folder, \"deepfake_detection/Synthetic_full_official.csv\")\n",
    "process_audio_files(synthetic_audio_folder, \"deepfake_detection/Synthetic_full_speechify.csv\") # Speechify\n",
    "\n",
    "# AI Hugging Face\n",
    "# ds = load_dataset(\"saahith/synthetic_with_val\")\n",
    "# ds = load_dataset(\"birgermoell/synthetic_compassion_wav\")\n",
    "# process_audio_files_hugging_face(ds, \"deepfake_detection/Synthetic_full_hf_birgermoell.csv\")\n",
    "\n",
    "# -----------------------------------------------------Speaker identification-------------------------------------------------------\n",
    "\n",
    "speaker_audio_folder = \"AudioData/speaker_audio/speaker_audio\"\n",
    "other_audio_folder = \"AudioData/speaker_audio/other_human_audio\"\n",
    "\n",
    "# for all\n",
    "# process_audio_files(speaker_audio_folder, \"voice_recognition/vr_speaker_all_features.csv\")\n",
    "# process_audio_files(other_audio_folder, \"voice_recognition/vr_other_all_features.csv\")\n",
    "\n",
    "# for mean\n",
    "# process_audio_files_mean(speaker_audio_folder, \"voice_recognition/training_mean/vr_speaker_mean_features2.csv\")\n",
    "# process_audio_files_mean(other_audio_folder, \"voice_recognition/training_mean/vr_other_mean_features2.csv\")\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87262dd6-2547-4e5a-8b42-2df84ab995db",
   "metadata": {},
   "source": [
    "# 8. For training only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fa85f40-7e0d-40c5-8612-afa50ea87916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'transcript', 'duration'],\n",
       "        num_rows: 405\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['audio', 'transcript', 'duration'],\n",
       "        num_rows: 86\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'transcript', 'duration'],\n",
       "        num_rows: 88\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c073f-e44d-48ba-bd4d-af25c916394a",
   "metadata": {},
   "source": [
    "# For Testing Extract 1 Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6869b66-911a-4eaa-baad-a8c3adbe3311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.0998273e+02 -4.8956113e+02 -4.8937140e+02 ... -4.9340005e+02\n",
      "  -4.9539423e+02 -5.0779730e+02]\n",
      " [ 5.0587605e+01  6.6524628e+01  6.6727997e+01 ...  5.9833664e+01\n",
      "   6.1890678e+01  5.5993782e+01]\n",
      " [ 2.4690987e+01  2.5347982e+01  2.4821363e+01 ...  3.2736610e+01\n",
      "   3.3107082e+01  3.4006363e+01]\n",
      " ...\n",
      " [-6.4265317e-01 -6.4265317e-01 -6.4265317e-01 ... -6.3449788e-01\n",
      "  -6.3449788e-01 -6.3449788e-01]\n",
      " [-1.3168605e-01 -1.3168605e-01 -1.3168605e-01 ... -5.3732771e-01\n",
      "  -5.3732771e-01 -5.3732771e-01]\n",
      " [ 4.8490107e-01  4.8490107e-01  4.8490107e-01 ... -5.6581754e-02\n",
      "  -5.6581754e-02 -5.6581754e-02]]\n",
      "True\n",
      "Number of processed files:  1\n",
      "Successfully saved combined features to voice_recognition//test_mean//vr_notsame_mean_test3.csv\n"
     ]
    }
   ],
   "source": [
    "#  For testing. Extracting 1 audio file\n",
    "\n",
    "loc = \"AudioData/test/voice_recognition_test\"\n",
    "# FULL\n",
    "# process_audio_files(loc, \"voice_recognition/test_full/vr_same_test4.csv\") #Change the file name\n",
    "\n",
    "# MEAN\n",
    "process_audio_files_mean(loc, \"voice_recognition//test_mean//vr_notsame_mean_test3.csv\") #Change the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d2157-c0f3-44c0-9b68-16f5ba931367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venvAudio)",
   "language": "python",
   "name": "pythonaudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
